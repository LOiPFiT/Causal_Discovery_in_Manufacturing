{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb75c789",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import Adam\n",
    "from fddbenchmark import FDDDataset, FDDDataloader, FDDEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb6128bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading data/small_tep/dataset.csv: 100%|██████████| 153300/153300 [00:00<00:00, 220756.71it/s]\n",
      "Reading data/small_tep/labels.csv: 100%|██████████| 153300/153300 [00:00<00:00, 3028085.97it/s]\n",
      "Reading data/small_tep/train_mask.csv: 100%|██████████| 153300/153300 [00:00<00:00, 3040083.61it/s]\n",
      "Reading data/small_tep/test_mask.csv: 100%|██████████| 153300/153300 [00:00<00:00, 2921405.77it/s]\n"
     ]
    }
   ],
   "source": [
    "data = FDDDataset(name='small_tep')\n",
    "data.df = (data.df - data.df.mean()) / data.df.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51ec13e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating sequence of samples: 100%|██████████| 105/105 [00:00<00:00, 978.56it/s]\n",
      "Creating sequence of samples: 100%|██████████| 105/105 [00:00<00:00, 799.12it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dl = FDDDataloader(\n",
    "    dataframe=data.df,\n",
    "    mask=data.train_mask,\n",
    "    labels=data.labels,\n",
    "    window_size=10,\n",
    "    step_size=1,\n",
    "    minibatch_training=True,\n",
    "    batch_size=1024,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_dl = FDDDataloader(\n",
    "    dataframe=data.df,\n",
    "    mask=data.test_mask,\n",
    "    labels=data.labels,\n",
    "    window_size=10, \n",
    "    step_size=1, \n",
    "    minibatch_training=True,\n",
    "    batch_size=1024\n",
    ")\n",
    "\n",
    "evaluator = FDDEvaluator(\n",
    "    step_size=test_dl.step_size\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cc3136",
   "metadata": {},
   "source": [
    "# MLP Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "094ba61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP Class\n",
    "\n",
    "def encode_onehot(labels):\n",
    "    classes = set(labels)\n",
    "    classes_dict = {c: np.identity(len(classes))[i, :] for i, c in\n",
    "                    enumerate(classes)}\n",
    "    labels_onehot = np.array(list(map(classes_dict.get, labels)),\n",
    "                             dtype=np.int32)\n",
    "    return labels_onehot\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    \"\"\"Two-layer fully-connected ELU net with batch norm.\"\"\"\n",
    "\n",
    "    def __init__(self, n_in, n_hid, n_out, do_prob=0.):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(n_in, n_hid)\n",
    "        self.fc2 = nn.Linear(n_hid, n_out)\n",
    "        self.bn = nn.BatchNorm1d(n_out)\n",
    "        self.dropout_prob = do_prob\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal(m.weight.data)\n",
    "                m.bias.data.fill_(0.1)\n",
    "            elif isinstance(m, nn.BatchNorm1d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def batch_norm(self, inputs):\n",
    "        x = inputs.view(inputs.size(0) * inputs.size(1), -1)\n",
    "        x = self.bn(x)\n",
    "        return x.view(inputs.size(0), inputs.size(1), -1)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Input shape: [num_sims, num_things, num_features]\n",
    "        x = F.elu(self.fc1(inputs))\n",
    "        x = F.dropout(x, self.dropout_prob, training=self.training)\n",
    "        x = F.elu(self.fc2(x))\n",
    "        return self.batch_norm(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b046b29",
   "metadata": {},
   "source": [
    "# Decoder Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62a5d1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPDecoder(nn.Module):\n",
    "    \"\"\"MLP decoder module.\"\"\"\n",
    "\n",
    "    def __init__(self, n_in_node, edge_types, msg_hid, msg_out, n_hid,\n",
    "                 do_prob=0., skip_first=False):\n",
    "        super(MLPDecoder, self).__init__()\n",
    "        self.msg_fc1 = nn.ModuleList(\n",
    "            [nn.Linear(2 * n_in_node, msg_hid) for _ in range(edge_types)])\n",
    "        self.msg_fc2 = nn.ModuleList(\n",
    "            [nn.Linear(msg_hid, msg_out) for _ in range(edge_types)])\n",
    "        self.msg_out_shape = msg_out\n",
    "        self.skip_first_edge_type = skip_first\n",
    "\n",
    "        self.out_fc1 = nn.Linear(n_in_node + msg_out, n_hid)\n",
    "        self.out_fc2 = nn.Linear(n_hid, n_hid)\n",
    "        self.out_fc3 = nn.Linear(n_hid, n_in_node)\n",
    "\n",
    "        print('Using learned interaction net decoder.')\n",
    "\n",
    "        self.dropout_prob = do_prob\n",
    "\n",
    "    def single_step_forward(self, single_timestep_inputs, rel_rec, rel_send,\n",
    "                            single_timestep_rel_type):\n",
    "\n",
    "        # single_timestep_inputs has shape\n",
    "        # [batch_size, num_timesteps, num_atoms, num_dims]\n",
    "\n",
    "        # single_timestep_rel_type has shape:\n",
    "        # [batch_size, num_timesteps, num_atoms*(num_atoms-1), num_edge_types]\n",
    "\n",
    "        # Node2edge\n",
    "        receivers = torch.matmul(rel_rec, single_timestep_inputs)\n",
    "        senders = torch.matmul(rel_send, single_timestep_inputs)\n",
    "        pre_msg = torch.cat([senders, receivers], dim=-1)\n",
    "\n",
    "        all_msgs = Variable(torch.zeros(pre_msg.size(0), pre_msg.size(1),\n",
    "                                        pre_msg.size(2), self.msg_out_shape))\n",
    "        if single_timestep_inputs.is_cuda:\n",
    "            all_msgs = all_msgs.cuda()\n",
    "\n",
    "        if self.skip_first_edge_type:\n",
    "            start_idx = 1\n",
    "        else:\n",
    "            start_idx = 0\n",
    "\n",
    "        # Run separate MLP for every edge type\n",
    "        # NOTE: To exlude one edge type, simply offset range by 1\n",
    "        for i in range(start_idx, len(self.msg_fc2)):\n",
    "            msg = F.relu(self.msg_fc1[i](pre_msg))\n",
    "            msg = F.dropout(msg, p=self.dropout_prob)\n",
    "            msg = F.relu(self.msg_fc2[i](msg))\n",
    "            msg = msg * single_timestep_rel_type[:, :, :, i:i + 1]\n",
    "            all_msgs += msg\n",
    "\n",
    "        # Aggregate all msgs to receiver\n",
    "        agg_msgs = all_msgs.transpose(-2, -1).matmul(rel_rec).transpose(-2, -1)\n",
    "        agg_msgs = agg_msgs.contiguous()\n",
    "\n",
    "        # Skip connection\n",
    "        aug_inputs = torch.cat([single_timestep_inputs, agg_msgs], dim=-1)\n",
    "\n",
    "        # Output MLP\n",
    "        pred = F.dropout(F.relu(self.out_fc1(aug_inputs)), p=self.dropout_prob)\n",
    "        pred = F.dropout(F.relu(self.out_fc2(pred)), p=self.dropout_prob)\n",
    "        pred = self.out_fc3(pred)\n",
    "\n",
    "        # Predict position/velocity difference\n",
    "        return single_timestep_inputs + pred\n",
    "\n",
    "    def forward(self, inputs, rel_type, rel_rec, rel_send, pred_steps=1):\n",
    "        # NOTE: Assumes that we have the same graph across all samples.\n",
    "\n",
    "        inputs = inputs.transpose(1, 2).contiguous()\n",
    "\n",
    "        sizes = [rel_type.size(0), inputs.size(1), rel_type.size(1),\n",
    "                 rel_type.size(2)]\n",
    "        rel_type = rel_type.unsqueeze(1).expand(sizes)\n",
    "\n",
    "        time_steps = inputs.size(1)\n",
    "        assert (pred_steps <= time_steps)\n",
    "        preds = []\n",
    "\n",
    "        # Only take n-th timesteps as starting points (n: pred_steps)\n",
    "        last_pred = inputs[:, 0::pred_steps, :, :]\n",
    "        curr_rel_type = rel_type[:, 0::pred_steps, :, :]\n",
    "        # NOTE: Assumes rel_type is constant (i.e. same across all time steps).\n",
    "\n",
    "        # Run n prediction steps\n",
    "        for step in range(0, pred_steps):\n",
    "            last_pred = self.single_step_forward(last_pred, rel_rec, rel_send,\n",
    "                                                 curr_rel_type)\n",
    "            preds.append(last_pred)\n",
    "\n",
    "        sizes = [preds[0].size(0), preds[0].size(1) * pred_steps,\n",
    "                 preds[0].size(2), preds[0].size(3)]\n",
    "\n",
    "        output = Variable(torch.zeros(sizes))\n",
    "        if inputs.is_cuda:\n",
    "            output = output.cuda()\n",
    "\n",
    "        # Re-assemble correct timeline\n",
    "        for i in range(len(preds)):\n",
    "            output[:, i::pred_steps, :, :] = preds[i]\n",
    "\n",
    "        pred_all = output[:, :(inputs.size(1) - 1), :, :]\n",
    "\n",
    "        return pred_all.transpose(1, 2).contiguous()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7db0f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_types = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52fc3026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using learned interaction net decoder.\n"
     ]
    }
   ],
   "source": [
    "decoder = MLPDecoder(n_in_node=1,\n",
    "                         edge_types=edge_types,\n",
    "                         msg_hid=32,\n",
    "                         msg_out=32,\n",
    "                         n_hid=32,\n",
    "                         do_prob=0.0,\n",
    "                         skip_first=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190a53f5",
   "metadata": {},
   "source": [
    "# Encoder Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e58e4eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate off-diagonal interaction graph\n",
    "off_diag = np.ones([52, 52]) - np.eye(52)\n",
    "\n",
    "rel_rec = np.array(encode_onehot(np.where(off_diag)[0]), dtype=np.float32)\n",
    "rel_send = np.array(encode_onehot(np.where(off_diag)[1]), dtype=np.float32)\n",
    "rel_rec = torch.FloatTensor(rel_rec)\n",
    "rel_send = torch.FloatTensor(rel_send)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da22e2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPEncoder(nn.Module):\n",
    "    def __init__(self, n_in, n_hid, n_out, do_prob=0., factor=True):\n",
    "        super(MLPEncoder, self).__init__()\n",
    "\n",
    "        self.factor = factor\n",
    "\n",
    "        self.mlp1 = MLP(n_in, n_hid, n_hid, do_prob)\n",
    "        self.mlp2 = MLP(n_hid * 2, n_hid, n_hid, do_prob)\n",
    "        self.mlp3 = MLP(n_hid, n_hid, n_hid, do_prob)\n",
    "        if self.factor:\n",
    "            self.mlp4 = MLP(n_hid * 3, n_hid, n_hid, do_prob)\n",
    "            print(\"Using factor graph MLP encoder.\")\n",
    "        else:\n",
    "            self.mlp4 = MLP(n_hid * 2, n_hid, n_hid, do_prob)\n",
    "            print(\"Using MLP encoder.\")\n",
    "        self.fc_out = nn.Linear(n_hid, n_out)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal(m.weight.data)\n",
    "                m.bias.data.fill_(0.1)\n",
    "\n",
    "    def edge2node(self, x, rel_rec, rel_send):\n",
    "        # NOTE: Assumes that we have the same graph across all samples.\n",
    "        incoming = torch.matmul(rel_rec.t(), x)\n",
    "        return incoming / incoming.size(1)\n",
    "\n",
    "    def node2edge(self, x, rel_rec, rel_send):\n",
    "        # NOTE: Assumes that we have the same graph across all samples.\n",
    "        receivers = torch.matmul(rel_rec, x)\n",
    "        senders = torch.matmul(rel_send, x)\n",
    "        edges = torch.cat([senders, receivers], dim=2)\n",
    "        return edges\n",
    "\n",
    "    def forward(self, inputs, rel_rec, rel_send):\n",
    "        # Input shape: [num_sims, num_atoms, num_timesteps, num_dims]\n",
    "        x = inputs #.view(inputs.size(0), inputs.size(1), -1)\n",
    "        # New shape: [num_sims, num_atoms, num_timesteps*num_dims]\n",
    "\n",
    "        x = self.mlp1(x)  # 2-layer ELU net per node\n",
    "\n",
    "        x = self.node2edge(x, rel_rec, rel_send)\n",
    "        x = self.mlp2(x)\n",
    "        x_skip = x\n",
    "\n",
    "        if self.factor:\n",
    "            x = self.edge2node(x, rel_rec, rel_send)\n",
    "            x = self.mlp3(x)\n",
    "            x = self.node2edge(x, rel_rec, rel_send)\n",
    "            x = torch.cat((x, x_skip), dim=2)  # Skip connection\n",
    "            x = self.mlp4(x)\n",
    "        else:\n",
    "            x = self.mlp3(x)\n",
    "            x = torch.cat((x, x_skip), dim=2)  # Skip connection\n",
    "            x = self.mlp4(x)\n",
    "\n",
    "        return self.fc_out(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f602d3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# енкодер:\n",
    "\n",
    "def my_softmax(input, axis=1):\n",
    "    trans_input = input.transpose(axis, 0).contiguous()\n",
    "    soft_max_1d = F.softmax(trans_input)\n",
    "    return soft_max_1d.transpose(axis, 0)\n",
    "\n",
    "def sample_gumbel(shape, eps=1e-10):\n",
    "    \"\"\"\n",
    "    NOTE: Stolen from https://github.com/pytorch/pytorch/pull/3341/commits/327fcfed4c44c62b208f750058d14d4dc1b9a9d3\n",
    "\n",
    "    Sample from Gumbel(0, 1)\n",
    "\n",
    "    based on\n",
    "    https://github.com/ericjang/gumbel-softmax/blob/3c8584924603869e90ca74ac20a6a03d99a91ef9/Categorical%20VAE.ipynb ,\n",
    "    (MIT license)\n",
    "    \"\"\"\n",
    "    U = torch.rand(shape).float()\n",
    "    return - torch.log(eps - torch.log(U + eps))\n",
    "\n",
    "\n",
    "def gumbel_softmax_sample(logits, tau=1, eps=1e-10):\n",
    "    \"\"\"\n",
    "    NOTE: Stolen from https://github.com/pytorch/pytorch/pull/3341/commits/327fcfed4c44c62b208f750058d14d4dc1b9a9d3\n",
    "\n",
    "    Draw a sample from the Gumbel-Softmax distribution\n",
    "\n",
    "    based on\n",
    "    https://github.com/ericjang/gumbel-softmax/blob/3c8584924603869e90ca74ac20a6a03d99a91ef9/Categorical%20VAE.ipynb\n",
    "    (MIT license)\n",
    "    \"\"\"\n",
    "    gumbel_noise = sample_gumbel(logits.size(), eps=eps)\n",
    "    if logits.is_cuda:\n",
    "        gumbel_noise = gumbel_noise.cuda()\n",
    "    y = logits + Variable(gumbel_noise)\n",
    "    return my_softmax(y / tau, axis=-1)\n",
    "\n",
    "def gumbel_softmax(logits, tau=1, hard=False, eps=1e-10):\n",
    "    \"\"\"\n",
    "    NOTE: Stolen from https://github.com/pytorch/pytorch/pull/3341/commits/327fcfed4c44c62b208f750058d14d4dc1b9a9d3\n",
    "\n",
    "    Sample from the Gumbel-Softmax distribution and optionally discretize.\n",
    "    Args:\n",
    "      logits: [batch_size, n_class] unnormalized log-probs\n",
    "      tau: non-negative scalar temperature\n",
    "      hard: if True, take argmax, but differentiate w.r.t. soft sample y\n",
    "    Returns:\n",
    "      [batch_size, n_class] sample from the Gumbel-Softmax distribution.\n",
    "      If hard=True, then the returned sample will be one-hot, otherwise it will\n",
    "      be a probability distribution that sums to 1 across classes\n",
    "\n",
    "    Constraints:\n",
    "    - this implementation only works on batch_size x num_features tensor for now\n",
    "\n",
    "    based on\n",
    "    https://github.com/ericjang/gumbel-softmax/blob/3c8584924603869e90ca74ac20a6a03d99a91ef9/Categorical%20VAE.ipynb ,\n",
    "    (MIT license)\n",
    "    \"\"\"\n",
    "    y_soft = gumbel_softmax_sample(logits, tau=tau, eps=eps)\n",
    "    if hard:\n",
    "        shape = logits.size()\n",
    "        _, k = y_soft.data.max(-1)\n",
    "        # this bit is based on\n",
    "        # https://discuss.pytorch.org/t/stop-gradients-for-st-gumbel-softmax/530/5\n",
    "        y_hard = torch.zeros(*shape)\n",
    "        if y_soft.is_cuda:\n",
    "            y_hard = y_hard.cuda()\n",
    "        y_hard = y_hard.zero_().scatter_(-1, k.view(shape[:-1] + (1,)), 1.0)\n",
    "        # this cool bit of code achieves two things:\n",
    "        # - makes the output value exactly one-hot (since we add then\n",
    "        #   subtract y_soft value)\n",
    "        # - makes the gradient equal to y_soft gradient (since we strip\n",
    "        #   all other gradients)\n",
    "        y = Variable(y_hard - y_soft.data) + y_soft\n",
    "    else:\n",
    "        y = y_soft\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eada51f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MLP encoder.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/conda/lib/python3.7/site-packages/ipykernel_launcher.py:26: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
      "/home/user/conda/lib/python3.7/site-packages/ipykernel_launcher.py:22: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n"
     ]
    }
   ],
   "source": [
    "encoder = MLPEncoder(10, 32, edge_types, 0.0, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "672e92a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll_gaussian(preds, target, variance, add_const=False):\n",
    "    neg_log_p = ((preds - target) ** 2 / (2 * variance))\n",
    "    if add_const:\n",
    "        const = 0.5 * np.log(2 * np.pi * variance)\n",
    "        neg_log_p += const\n",
    "    return neg_log_p.sum() / (target.size(0) * target.size(1))\n",
    "\n",
    "def kl_categorical(preds, log_prior, num_atoms, eps=1e-16):\n",
    "    kl_div = preds * (torch.log(preds + eps) - log_prior)\n",
    "    return kl_div.sum() / (num_atoms * preds.size(0))\n",
    "\n",
    "\n",
    "def kl_categorical_uniform(preds, num_atoms, num_edge_types, add_const=False,\n",
    "                           eps=1e-16):\n",
    "    kl_div = preds * torch.log(preds + eps)\n",
    "    if add_const:\n",
    "        const = np.log(num_edge_types)\n",
    "        kl_div += const\n",
    "    return kl_div.sum() / (num_atoms * preds.size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c66a0f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/conda/lib/python3.7/site-packages/ipykernel_launcher.py:5: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_192/2339437418.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrel_rec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrel_send\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0medges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgumbel_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtau\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhard\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.imgenv-baseline-0/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_192/1315376770.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, rel_rec, rel_send)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 2-layer ELU net per node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode2edge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrel_rec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrel_send\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mx_skip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_192/1315376770.py\u001b[0m in \u001b[0;36mnode2edge\u001b[0;34m(self, x, rel_rec, rel_send)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# NOTE: Assumes that we have the same graph across all samples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mreceivers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrel_rec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0msenders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrel_send\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0medges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msenders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreceivers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0medges\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "corr = data.df.corr(method='pearson')\n",
    "coef = 0.7\n",
    "A = torch.FloatTensor(corr.values)\n",
    "A[(A > coef) | (A < -coef)] = 1\n",
    "A[A < 1] = 0\n",
    "device = torch.device(\"cuda\")\n",
    "print(device)\n",
    "optimizer = Adam(list(encoder.parameters()) + list(decoder.parameters()),\n",
    "                       lr=0.001)\n",
    "n_epochs = 5\n",
    "encoder.train()\n",
    "\n",
    "a = None\n",
    "for e in range(n_epochs):\n",
    "    for train_ts, train_index, train_label in train_dl:\n",
    "        ts = torch.FloatTensor(train_ts)\n",
    "        ts = torch.transpose(ts, 1, 2)\n",
    "        optimizer.zero_grad()\n",
    "        logits = encoder(ts, rel_rec, rel_send)\n",
    "        edges = gumbel_softmax(logits, tau=0.5, hard=False)\n",
    "        prob = my_softmax(logits, -1)\n",
    "        ts = ts.unsqueeze(dim=3)\n",
    "        output = decoder(ts, edges, rel_rec, rel_send, 1)\n",
    "        target = ts[:, :, 1:, :]\n",
    "        loss_nll = nll_gaussian(output, target, 5e-5)\n",
    "        loss_kl = kl_categorical_uniform(prob, 52, edge_types)\n",
    "        loss = loss_nll + loss_kl\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#torch.save(encoder.state_dict(), 'encoder.pt')\n",
    "#torch.save(decoder.state_dict(), 'decoder.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5609f856",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "d84a307c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 52, 9, 1])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.unsqueeze(dim=3)[:, :, 1:, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5046d99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.unsqueeze(dim=3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6c42baf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 10, 52])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = ts.transpose(1, 2).contiguous()\n",
    "ts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3bb80d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 2652, 1])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "675c1fb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.size(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1d54b733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2652"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges.size(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ec5fd41e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges.size(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0b6346d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 10, 2652, 1])\n"
     ]
    }
   ],
   "source": [
    "sizes = [256,10,2652,1]\n",
    "rel_type = edges.unsqueeze(1).expand(sizes)\n",
    "print(rel_type.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7871f13f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 10, 52])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4415e2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ts[:, 0::1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b338a5e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 10, 52])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af599fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = [256,10,2652,1]\n",
    "rel_type = rel_type.unsqueeze(1).expand(sizes)\n",
    "\n",
    "time_steps = inputs.size(1)\n",
    "assert (pred_steps <= time_steps)\n",
    "preds = []\n",
    "print(time_steps)\n",
    "\n",
    "# Only take n-th timesteps as starting points (n: pred_steps)\n",
    "last_pred = inputs[:, 0::pred_steps, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b51b1524",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7j/0_jgxqhn7k50rhvm66spy_y40000gn/T/ipykernel_56966/1243628766.py:75: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  soft_max_1d = F.softmax(trans_input)\n"
     ]
    }
   ],
   "source": [
    "edges = gumbel_softmax(logits, tau=0.5, hard=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9177a970",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/conda/lib/python3.7/site-packages/ipykernel_launcher.py:5: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "prob = my_softmax(logits, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0ac4c2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         ...,\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         ...,\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         ...,\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         ...,\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         ...,\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         ...,\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]]], grad_fn=<TransposeBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce48bdae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.7154],\n",
       "         [ 1.5010],\n",
       "         [ 0.7967],\n",
       "         ...,\n",
       "         [-1.4997],\n",
       "         [-2.1056],\n",
       "         [-0.8520]],\n",
       "\n",
       "        [[ 1.7129],\n",
       "         [ 1.2555],\n",
       "         [-1.1899],\n",
       "         ...,\n",
       "         [-3.4767],\n",
       "         [-0.0178],\n",
       "         [-1.4288]],\n",
       "\n",
       "        [[ 2.9453],\n",
       "         [ 2.5366],\n",
       "         [ 2.7629],\n",
       "         ...,\n",
       "         [ 0.7023],\n",
       "         [ 2.2458],\n",
       "         [-1.6868]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 2.6564],\n",
       "         [ 0.3357],\n",
       "         [ 0.3521],\n",
       "         ...,\n",
       "         [ 0.4581],\n",
       "         [ 0.3857],\n",
       "         [ 0.5502]],\n",
       "\n",
       "        [[ 1.0119],\n",
       "         [-0.1681],\n",
       "         [ 1.8196],\n",
       "         ...,\n",
       "         [-1.8215],\n",
       "         [-1.1519],\n",
       "         [-0.9417]],\n",
       "\n",
       "        [[-0.8506],\n",
       "         [-0.6669],\n",
       "         [-0.1034],\n",
       "         ...,\n",
       "         [-0.9253],\n",
       "         [ 2.7951],\n",
       "         [ 1.9839]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b0b1b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 2652, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba90d8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('A.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "406416d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_192/1676823408.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'train'"
     ]
    }
   ],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
